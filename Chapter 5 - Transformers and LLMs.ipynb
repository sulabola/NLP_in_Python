{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5371c45-5a3c-48f7-83d1-a11f1001216f",
   "metadata": {},
   "source": [
    "### Transformers and LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17158e38-72b5-4234-9ad2-7c5f4a9d1a54",
   "metadata": {},
   "source": [
    "Transformers are the architecture behind ChatGPT and many other powerful LLMs (Large Language models).\n",
    "\n",
    "LLMs are specifically designed to perform NLP tasks.\n",
    "\n",
    "In this chapter, we will discuss the details of Transformers and LLMs. Then we dive into three main layers of transformers: embedding layers, attention layers, and an FNN layer. Next, we will be discussing categories of transformers: encoder, decoder, and encoder & decoder models. Last, we discuss details of popular LLMs: GPT, BERT,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0b5bd-d6c2-4c89-bd18-a7fe9ffb5d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
